{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.8.16","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceId":7723170,"sourceType":"datasetVersion","datasetId":4511660}],"dockerImageVersionId":30459,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Whisper JAX ‚ö°Ô∏è\n\nThis Kaggle notebook demonstratese how to run Indic Whisper JAX on a TPU v3-8. Indic Whisper JAX is a highly optimised JAX implementation of the Indic Whisper model by AI4Bharat,n. Compared to OpenAI's PyTorch code, Whisper JAX runs over **70x faster**, making it the fastest Whisper implementation available.\n\nYou can find the code [here](https://github.com/sanchit-gandhi/whisper-jax).","metadata":{}},{"cell_type":"markdown","source":"## Let's get started!\n\nThe first thing we need to do is connect to a TPU. Kaggle offers 20 hours of TPU v3-8 usage per month for free, which we'll make use of for this notebook. Refer to the guide [Introducing TPUs to Kaggle](https://www.kaggle.com/product-feedback/129828) for more information on TPU quotas in Kaggle.\n\nYou will need to register a Kaggle account and verify your phone number if you haven't done so already. Once verified, open up the settings menu in the Notebook editor (the small arrow in the bottom right). Then under _Notebook options_, select ‚ÄòTPU VM v3-8‚Äô from the _Accelerator_ menu. You will also need to toggle the internet switch so that it is set to \"on\".\n\nOnce we've got a TPU allocated (there might be a queue to get one!), we can run the following to see the TPU devices we have available:","metadata":{}},{"cell_type":"code","source":"import jax\njax.devices()","metadata":{"execution":{"iopub.status.busy":"2024-02-29T05:46:11.210228Z","iopub.execute_input":"2024-02-29T05:46:11.210789Z","iopub.status.idle":"2024-02-29T05:46:18.699550Z","shell.execute_reply.started":"2024-02-29T05:46:11.210763Z","shell.execute_reply":"2024-02-29T05:46:18.698592Z"},"trusted":true},"execution_count":1,"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"[TpuDevice(id=0, process_index=0, coords=(0,0,0), core_on_chip=0),\n TpuDevice(id=1, process_index=0, coords=(0,0,0), core_on_chip=1),\n TpuDevice(id=2, process_index=0, coords=(1,0,0), core_on_chip=0),\n TpuDevice(id=3, process_index=0, coords=(1,0,0), core_on_chip=1),\n TpuDevice(id=4, process_index=0, coords=(0,1,0), core_on_chip=0),\n TpuDevice(id=5, process_index=0, coords=(0,1,0), core_on_chip=1),\n TpuDevice(id=6, process_index=0, coords=(1,1,0), core_on_chip=0),\n TpuDevice(id=7, process_index=0, coords=(1,1,0), core_on_chip=1)]"},"metadata":{}}]},{"cell_type":"markdown","source":"Cool! We've got 8 TPU devices packaged into one accelerator.\n\nKaggle TPUs come with JAX pre-installed, so we can directly install the remaining Python packages. If you're running the notebook on a Cloud TPU, ensure you have installed JAX according to the official [installation guide](https://github.com/google/jax#pip-installation-google-cloud-tpu). \n\nWe'll install [Whisper JAX](https://github.com/sanchit-gandhi/whisper-jax) from main, as well as `datasets` and `librosa` for loading audio files:","metadata":{}},{"cell_type":"code","source":"!pip install --quiet --upgrade pip\n!pip install --quiet git+https://github.com/sanchit-gandhi/whisper-jax.git datasets librosa tqdm","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","tags":[],"execution":{"iopub.status.busy":"2024-02-29T05:46:52.281467Z","iopub.execute_input":"2024-02-29T05:46:52.281925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Loading the Pipeline\n\nThe recommended way of running Whisper JAX is through the [`FlaxWhisperPipline`](https://github.com/sanchit-gandhi/whisper-jax/blob/main/whisper_jax/pipeline.py#L57) class. This class handles all the necessary pre- and post-processing for the model, as well as wrapping the generate method for data parallelism across all available accelerator devices\n\n\nLet's load the large-v2 model in bfloat16 (half-precision). Using half-precision will speed-up the computation quite considerably by storing intermediate tensors in half-precision. There is no change to the precision of the model weights.\n\nWe'll also make use of _batching_ for single audio inputs: the audio is first chunked into 30 second segments, and then chunks dispatched to the model to be transcribed in parallel. By batching an audio input and transcribing it in parallel, we get a ~10x speed-up compared to transcribing the audio samples sequentially.","metadata":{}},{"cell_type":"code","source":"from whisper_jax import FlaxWhisperPipline\nimport jax.numpy as jnp\n\npipeline = FlaxWhisperPipline(\"parthiv11/indic_whisper_hi_multi_gpu\", dtype=jnp.bfloat16, batch_size=16)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We'll then initialise a compilation cache, which will speed-up the compilation time if we close our kernel and want to compile the model again:","metadata":{}},{"cell_type":"code","source":"%cd /kaggle/working\nfrom jax.experimental.compilation_cache import compilation_cache as cc\n\ncc.initialize_cache(\"./jax_cache\")","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## üé∂ Load an audio file\n\nLet's load up a long audio file for our tests.Note that you can also pass in any `.mp3`, `.wav` or `.flac` audio file directly to the Whisper JAX pipeline, and it will take care of loading the audio file for you.","metadata":{}},{"cell_type":"markdown","source":"We can take a listen to the audio file that we've loaded - we'll see that it's approximately 5 mins long:","metadata":{}},{"cell_type":"code","source":"# _6900884053.mp3' is 0 seconds not work\nfile_path='//kaggle/working/2_hours_hanuman.wav/Rasraj Ji Maharaj - Hanuman Chalisa Bajrang Baan Sundarkand Paath Bhakti & More  TRSH 232.mp4'","metadata":{"execution":{"iopub.status.busy":"2024-02-28T22:29:39.345867Z","iopub.execute_input":"2024-02-28T22:29:39.346216Z","iopub.status.idle":"2024-02-28T22:29:39.350924Z","shell.execute_reply.started":"2024-02-28T22:29:39.346190Z","shell.execute_reply":"2024-02-28T22:29:39.349948Z"},"trusted":true},"execution_count":97,"outputs":[]},{"cell_type":"code","source":"from IPython.display import Audio\n\nAudio(file_path)","metadata":{"execution":{"iopub.status.busy":"2024-02-28T22:24:28.911103Z","iopub.execute_input":"2024-02-28T22:24:28.911523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import librosa\n\n# Load the audio file\nwaveform, sample_rate = librosa.load(file_path)\n\n# Print waveform shape and sample rate\nprint(\"Waveform shape:\", waveform.shape)\nprint(\"Sample rate:\", sample_rate)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Run the model\n\nNow we're ready to transcribe! We'll need to compile the `pmap` function the first time we use it. You can expect compilation to take ~2 minutes on a TPU v3-8 with a batch size of 16. Enough time to grab a coffee ‚òïÔ∏è\n\nThereafter, we can use our cached `pmap` function, which you'll see is amazingly fast.","metadata":{}},{"cell_type":"code","source":"# JIT compile the forward call - slow, but we only do once\n%time text= pipeline(waveform)","metadata":{"execution":{"iopub.status.busy":"2024-02-28T22:30:14.593656Z","iopub.execute_input":"2024-02-28T22:30:14.594246Z","iopub.status.idle":"2024-02-28T22:30:18.534988Z","shell.execute_reply.started":"2024-02-28T22:30:14.594192Z","shell.execute_reply":"2024-02-28T22:30:18.534027Z"},"trusted":true},"execution_count":99,"outputs":[{"name":"stderr","text":"WARNING:whisper_jax.pipeline:Numpy array passed as input - no sampling rate checks will be performed.It is strongly recommended to pass the input as a dictionary with an 'array' key containing the numpy array representing the audio, and a 'sampling_rate' key containing the sampling rate associated with the audio array.Failing to do so can result in silent errors that might be hard to debug.\n","output_type":"stream"},{"name":"stdout","text":"CPU times: user 23.3 s, sys: 39.9 s, total: 1min 3s\nWall time: 3.93 s\n","output_type":"stream"}]},{"cell_type":"code","source":"# used cached function thereafter - super fast!\n%time text= pipeline(waveform,task='transcribe',language='<|gu|>')\ntext","metadata":{"execution":{"iopub.status.busy":"2024-02-28T22:38:37.875250Z","iopub.execute_input":"2024-02-28T22:38:37.875596Z","iopub.status.idle":"2024-02-28T22:38:41.806432Z","shell.execute_reply.started":"2024-02-28T22:38:37.875570Z","shell.execute_reply":"2024-02-28T22:38:41.805689Z"},"trusted":true},"execution_count":109,"outputs":[{"name":"stderr","text":"WARNING:whisper_jax.pipeline:Numpy array passed as input - no sampling rate checks will be performed.It is strongly recommended to pass the input as a dictionary with an 'array' key containing the numpy array representing the audio, and a 'sampling_rate' key containing the sampling rate associated with the audio array.Failing to do so can result in silent errors that might be hard to debug.\n","output_type":"stream"},{"name":"stdout","text":"CPU times: user 23.5 s, sys: 39.9 s, total: 1min 3s\nWall time: 3.92 s\n","output_type":"stream"},{"execution_count":109,"output_type":"execute_result","data":{"text/plain":"{'text': '‡§π‡•á‡§≤‡•ã ‡§®‡§Æ‡§∏‡•ç‡§ï‡§æ‡§∞ ‡§∏‡§∞ ‡§Æ‡•à‡§Ç ‡§°‡§ø‡§™‡§æ‡§∞‡•ç‡§ü‡§Æ‡•á‡§Ç‡§ü ‡§ë‡§´‡§º ‡§∏‡•á‡§°‡§Æ‡§ø‡§®‡§ø‡§∏‡•ç‡§ü‡•á‡§ü‡•Ä ‡§°‡§ø‡§™‡§æ‡§∞‡•ç‡§ü‡§Æ‡•á‡§Ç‡§ü ‡§∏‡§Ç‡§™‡§§‡•ç‡§§‡§ø ‡§ú‡§ø‡§∏‡§ï‡•Ä ‡§§‡§∞‡§´ ‡§ê‡§∏‡•Ä ‡§∏‡§≠‡•ç‡§Ø ‡§ï‡§æ ‡§¨‡§æ‡§§ ‡§ï‡§∞‡•Ç‡§Å ‡§ï‡•ç‡§Ø‡§æ ‡§Æ‡•á‡§∞‡•Ä ‡§¨‡§∏ ‡§∂‡•ç‡§Ø‡§æ‡§Æ ‡§µ‡§ø‡§∂‡•ç‡§µ‡§∞‡§ø‡§Ø‡•ã‡§Ç ‡§∏‡•á ‡§®‡§π‡•Ä‡§Ç ‡§µ‡•ã ‡§â‡§∏‡§ï‡•ã ‡§™‡•á‡§∞‡§ø‡§∏ ‡§¨‡•ã‡§≤ ‡§∞‡§π‡§æ ‡§π‡•Ç‡§Å ‡§ú‡•Ä ‡§∏‡§∞ ‡§Æ‡•à‡§Ç ‡§â‡§®‡•ç‡§π‡•ã‡§Ç‡§®‡•á ‡§Æ‡•á‡§Ç ‡§≤‡§ø‡§ñ‡•Ä ‡§Ö‡§™‡§®‡•Ä ‡§∂‡§ø‡§ï‡§æ‡§Ø‡§§ ‡§¶‡§∞‡•ç‡§ú ‡§ï‡§ø‡§Ø‡§æ ‡§•‡§æ ‡§∏‡§§‡•ç‡§§‡§æ‡§à‡§∏ ‡§Ö‡§ó‡§∏‡•ç‡§§ ‡§ï‡•ã ‡§¶‡•ã ‡§π‡§ú‡§æ‡§∞ ‡§§‡•á‡§à‡§∏ ‡§Æ‡•á‡§Ç ‡§ï‡•ç‡§Ø‡§æ ‡§Ü‡§™‡§ï‡•ã ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§π‡•ã‡§ó‡•Ä ‡§á‡§∏‡§ï‡•á ‡§¨‡§æ‡§∞‡•á ‡§Æ‡•á‡§Ç ‡§π‡§æ‡§Å ‡§•‡•ã‡§°‡§º‡§æ ‡§π‡•à ‡§¨‡•ã‡§≤‡•á ‡§ú‡•Ä ‡§∏‡§∞ ‡§á‡§∏‡•Ä ‡§ï‡§æ ‡§∂‡§ø‡§ï‡§æ‡§Ø‡§§ ‡§∏‡§Ç‡§ñ‡•ç‡§Ø‡§æ ‡§π‡•à ‡§ú‡•Ä‡§∞‡•ã ‡§µ‡§® ‡§∏‡•á‡§µ ‡§°‡§¨‡§≤ ‡§∏‡•á‡§Æ ‡§´‡§æ‡§á‡§µ ‡§•‡•ç‡§∞‡•Ä ‡§∏‡§ø‡§∞ ‡§Ü‡§™ ‡§ê‡§∏‡•Ä ‡§ú‡§æ‡§®‡§®‡§æ ‡§ö‡§æ‡§π‡•á‡§Ç‡§ó‡•á ‡§ï‡•Ä ‡§Ü‡§™‡§ï‡•ã ‡§™‡•ç‡§∞‡§¶‡•á‡§∂ ‡§ï‡§æ ‡§∞‡§ø‡§™‡•ç‡§≤‡§æ‡§à ‡§ú‡§µ‡§æ‡§¨ ‡§°‡§ø‡§™‡§æ‡§∞‡•ç‡§ü‡§Æ‡•á‡§Ç‡§ü ‡§ï‡•á ‡§¶‡•ç‡§µ‡§æ‡§∞‡§æ ‡§ó‡•ç‡§Ø‡§æ‡§∞‡§π ‡§∏‡§ø‡§§‡§Æ‡•ç‡§¨‡§∞ ‡§ï‡•ã ‡§¶‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ ‡§π‡•à ‡§ï‡•Ä ‡§Ü‡§™‡§®‡•á ‡§ê‡§∏‡•Ä ‡§ö‡•á‡§ï ‡§ï‡§∞ ‡§≤‡§ø‡§Ø‡§æ ‡§î‡§∞ ‡§Ö‡§®‡§ï‡•ã‡§∂ ‡§†‡§æ‡§ï‡•Å‡§∞ ‡§∞‡•Ç‡§™‡§Ø‡§æ ‡§á‡§∏‡§∏‡•á ‡§î‡§∞ ‡§ï‡•ã‡§à ‡§Ö‡§µ‡§æ‡§∞‡•ç‡§° ‡§ï‡•á ‡§≤‡§ø‡§è ‡§® ‡§Æ‡•à‡§°‡§Æ ‡§á‡§∏‡§≤‡§ø‡§è ‡§Ø‡•á ‡§ï‡§ø‡§Ø‡§æ ‡§•‡§æ ‡§ú‡•Ä ‡§ú‡•Ä ‡§ú‡•Ä ‡§∏‡§¨‡§ï‡•ã ‡§π‡§Æ ‡§¨‡§§‡§æ ‡§¶‡§§‡•á ‡§π‡•à‡§Ç ‡§ï‡•Ä ‡§â‡§®‡•ç‡§π‡•ã‡§Ç‡§®‡•á ‡§ï‡§ø‡§∏ ‡§™‡•ç‡§∞‡§ï‡§æ‡§∞ ‡§Æ‡•á‡§Ç ‡§Ø‡•á ‡§∂‡§ø‡§ï‡§æ‡§Ø‡§§ ‡§¶‡§∞‡•ç‡§ú ‡§ï‡•Ä ‡§§‡•ã ‡§Ø‡§π ‡§¶‡§∞‡•ç‡§ú ‡§¶‡§Ø‡§æ ‡§¶‡§Ø‡§æ ‡§ú‡•Ä ‡§ú‡•Ä ‡§î‡§∞ ‡§µ‡§æ‡§∞‡•ç‡§° ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ï‡§ø‡§Ø‡§æ ‡§•‡§æ ‡§® ‡§ú‡•Ä ‡§ú‡•Ä ‡§¨‡§ø‡§≤‡•ç‡§ï‡•Å‡§≤ ‡§∏‡§∞ ‡§î‡§∞ ‡§µ‡§æ‡§∞‡•ç‡§° ‡§∏‡•á ‡§∞‡§ø‡§≤‡•á‡§ü‡•á‡§° ‡§Æ‡•á‡§Ç ‡§ï‡•Ä ‡§∂‡§ø‡§ï‡§æ‡§Ø‡§§ ‡§•‡•Ä ‡§π‡§æ‡§Å ‡§π‡§æ‡§Å ‡§ú‡•Ä ‡§ú‡•Ä ‡§∏‡§∞ ‡§§‡•ã ‡§Ü‡§™‡§ï‡•ã ‡§ú‡§ø‡§∏‡§ï‡§æ ‡§∞‡§ø‡§∏‡•ç‡§™‡•ç‡§≤‡§æ‡§à ‡§¶‡§ø‡§ú‡§µ‡§æ‡§¨ ‡§Ü‡§∞‡•ã‡§™ ‡§°‡§ø‡§™‡§æ‡§∞‡•ç‡§ü‡§Æ‡•á‡§Ç‡§ü ‡§ï‡•á ‡§¶‡•ç‡§µ‡§æ‡§∞‡§æ ‡§ó‡•ç‡§Ø‡§æ‡§∞‡§π ‡§∏‡§ø‡§§‡§Æ‡•ç‡§¨‡§∞ ‡§ï‡•ã ‡§¶‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ ‡§π‡•à ‡§ï‡•Ä ‡§Ü ‡§Ü‡§™‡§®‡•á ‡§â‡§∏‡•á ‡§ö‡•á‡§ï ‡§ï‡§∞ ‡§≤‡§ø‡§Ø‡§æ ‡§π‡•à ‡§Ü‡§™ ‡§ö‡•á‡§ï ‡§®‡§π‡•Ä‡§Ç ‡§ï‡§ø‡§Ø‡§æ ‡§®‡§π‡•Ä‡§Ç ‡§ï‡§ø‡§Ø‡§æ ‡§Ö‡§¨ ‡§≠‡•Ä ‡§ö‡•á‡§ï ‡§®‡§π‡•Ä‡§Ç ‡§ï‡§ø‡§Ø‡§æ ‡§π‡•à ‡§Ü‡§™‡§®‡•á ‡§ú‡•Ä ‡§∏‡§ø‡§∞ ‡§Ø‡§¶‡§ø ‡§Ü‡§™‡§®‡•á ‡§â‡§∏‡•á ‡§ö‡•á‡§ï ‡§®‡§π‡•Ä‡§Ç ‡§ï‡§ø‡§Ø‡§æ ‡§§‡•ã ‡§π‡§Æ ‡§Ü‡§™‡§ï‡•ã ‡§¨‡§§‡§æ ‡§¶‡•á‡§§‡•á ‡§π‡•à ‡§ï‡•Ä ‡§á‡§∏‡§Æ‡•á‡§Ç ‡§Ü‡§™‡§ï‡•ã ‡§ï‡•ç‡§Ø‡§æ ‡§ú‡§µ‡§æ‡§¨ ‡§¶‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ ‡§π‡•à ‡§á‡§∏‡§Æ‡•á‡§Ç ‡§∏‡§Æ‡•Ä‡§ï‡•ç‡§∑‡§æ ‡§ú‡§æ‡§§‡§æ ‡§π‡•à ‡§ï‡•Ä ‡§Ü‡§™‡§∏‡•á ‡§Ö‡§®‡•Å‡§∞‡•ã‡§ß ‡§π‡•à ‡§ï‡•Ä ‡§ï‡•É‡§™‡•ç‡§Ø‡§æ ‡§®‡§ø‡§∞‡•ç‡§Æ‡§ø‡§§ ‡§™‡•ã‡§∞‡•ç‡§ü‡§≤ ‡§Ü‡§∞‡•ã‡§™ ‡§™‡•Å‡§∞‡§∏‡•ç‡§ï‡§æ‡§∞ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Ü‡§µ‡•á‡§¶‡§® ‡§ï‡§∞‡•á ‡§∏‡§ø‡§∞ ‡§Ø‡§π ‡§ú‡§µ‡§æ‡§¨ ‡§â‡§∏‡§ï‡§æ ‡§°‡§ø‡§™‡§æ‡§∞‡•ç‡§ü‡§Æ‡•á‡§Ç‡§ü ‡§ï‡•á ‡§¶‡•ç‡§µ‡§æ‡§∞‡§æ ‡§¶‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ ‡§π‡•à ‡§∏‡§ø‡§∞ ‡§§‡•ã ‡§ï‡•ç‡§Ø‡§æ ‡§Ü‡§™‡§ï‡•á ‡§ú‡§µ‡§æ‡§¨ ‡§ê‡§∏‡•Ä ‡§∏‡§Ç‡§§‡•Å‡§∑‡•ç‡§ü ‡§π‡•à ‡§î‡§∞ ‡§∏‡§Ç‡§§‡•Å‡§∑‡•ç‡§ü ‡§π‡•à ‡§Ü‡§™ ‡§ï‡•ç‡§Ø‡§æ ‡§¨‡•ã‡§≤‡•á ‡§î‡§∞ ‡§è‡§ï ‡§¨‡§æ‡§∞ ‡§∞‡§ø‡§™‡•ã‡§∞‡•ç‡§ü ‡§ï‡•Ä‡§ú‡§ø‡§Ø‡•á ‡§µ‡§ó‡•à‡§∞‡§π ‡§ï‡•Ä ‡§Ü‡§™‡§ï‡•á ‡§Ö‡§®‡•Å‡§∞‡•ã‡§ß ‡§π‡•à ‡§ï‡•Ä ‡§ï‡•É‡§™‡•ç‡§Ø‡§æ ‡§®‡§ø‡§∞‡•ç‡§Æ‡§ø‡§§ ‡§™‡•ã‡§∞‡•ç‡§ü‡§≤ ‡§Ü‡§∞‡•ã‡§™ ‡§™‡•Å‡§∞‡§∏‡•ç‡§ï‡§æ‡§∞ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Ü‡§µ‡•á‡§¶‡§® ‡§ï‡§∞‡•á‡§Ç ‡§∏‡§ø‡§∞ ‡§Ü‡§™ ‡§ú‡•Ä‡§§ ‡§π‡•à ‡§Ø‡•á ‡§ú‡§µ‡§æ‡§¨ ‡§Ü‡§™‡§ï‡•ã ‡§¶‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ ‡§π‡•à ‡§°‡§ø‡§™‡§æ‡§∞‡•ç‡§ü‡§Æ‡•á‡§Ç‡§ü ‡§ï‡•á ‡§¶‡•ç‡§µ‡§æ‡§∞‡§æ ‡§§‡•ã ‡§Ü‡§™‡§ï‡•á ‡§ú‡§µ‡§æ‡§¨ ‡§ê‡§∏‡•Ä ‡§∏‡§Ç‡§§‡•Å‡§∑‡•ç‡§ü ‡§π‡•à ‡§π‡•à ‡§∏‡§¨ ‡§∏‡•Å‡§Ç‡§¶‡§∞‡§§‡•Ä ‡§π‡•à ‡§ú‡•Ä ‡§∏‡§∞ ‡§Ü‡§™ ‡§∞‡•á‡§ü‡§ø‡§Ç‡§ó ‡§ï‡§æ ‡§¶‡•á‡§®‡§æ ‡§ö‡§æ‡§π‡•á‡§Ç‡§ó‡•á ‡§∏‡§Ç‡§§‡•Å‡§∑‡•ç‡§ü ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ó‡•Å‡§° ‡§™‡•à‡§∞‡•Ä ‡§ó‡•Å‡§° ‡§Ø‡§æ ‡§è‡§ï‡•ç‡§∏‡•á‡§≤‡§Æ ‡§†‡•Ä‡§ï ‡§π‡•à ‡§è‡§ï‡•ç‡§∏‡•á‡§≤‡§Æ‡•á‡§Ç‡§ü ‡§ï‡•á ‡§π‡•ã‡§ó‡§æ ‡§•‡•à‡§Ç‡§ï‡•ç‡§Ø‡•Ç ‡§∏‡•á ‡§π‡•ã ‡§Æ‡§π‡•ã‡§§‡•ç‡§∏‡§µ ‡§á‡§∏‡§ï‡•á ‡§Ö‡§§‡§ø‡§∞‡§ø‡§ï‡•ç‡§§ ‡§Ü‡§™‡§§ ‡§Æ‡•á‡§Ç ‡§î‡§∞ ‡§ï‡•Å‡§õ ‡§∏‡•Å‡§ù‡§æ‡§µ ‡§ï‡•ã ‡§µ‡§ø‡§ö‡§æ‡§∞‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§¨‡§§‡§æ‡§®‡§æ ‡§ö‡§æ‡§π‡•á‡§Ç‡§ó‡•á ‡§ú‡§ø‡§∏‡§∏‡•á ‡§∏‡§∞‡•ç‡§µ‡§ø‡§∏ ‡§Æ‡•á‡§Ç ‡§∏‡•Å‡§ß‡§æ‡§∞ ‡§ï‡§ø‡§è ‡§ú‡§æ ‡§∏‡§ï‡•á‡§ï‡§æ ‡§∏‡§∞ ‡§Ø‡•á ‡§´‡•Ä‡§°‡§¨‡§ï ‡§π‡§Æ ‡§Æ‡•á‡§Ç‡§∂‡§® ‡§ï‡§∞‡§ï‡•á ‡§Ü‡§ó‡•á ‡§ï‡§∞ ‡§¶‡•á ‡§§‡•ã ‡§§‡§æ‡§ï‡§ø ‡§Ü‡§™‡§ï‡•ã ‡§ê‡§∏‡•Ä ‡§∏‡•Å‡§µ‡§ø‡§ß‡§æ ‡§Æ‡§ø‡§≤‡§§‡•Ä ‡§∞‡§π‡•á ‡§î‡§∞ ‡§≠‡§µ‡§ø‡§∑‡•ç‡§Ø ‡§Æ‡•á‡§Ç ‡§Ü‡§™‡§ï‡•ã ‡§ï‡•ã‡§à ‡§≠‡•Ä ‡§∞‡§ø‡§µ‡§æ‡§Ç‡§ö ‡§≤‡§æ‡§Ç‡§ö ‡§ï‡§∞‡§§‡•á ‡§§‡•ã ‡§Ü‡§™‡§ï‡•ã ‡§ê‡§∏‡•á ‡§π‡•Ä ‡§ú‡§≤‡•ç‡§¶ ‡§ê‡§∏‡•Ä ‡§ú‡§≤‡•ç‡§¶ ‡§∏‡§Æ‡§æ‡§ß‡§æ‡§® ‡§¶‡§ø‡§è ‡§ú‡§æ‡§è ‡§∏‡§ø‡§∞‡•Ä‡§Æ‡§§‡•Ä ‡§∏‡§Æ‡§Ø ‡§¶‡•á‡§®‡•á ‡§ï‡•ã ‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶ ‡§Ü‡§™‡§ï‡§æ ‡§¶‡§ø‡§® ‡§∂‡•Å‡§≠ ‡§π‡•ã ‡§∏‡§ï‡§§‡§æ ‡§π‡•à'}"},"metadata":{}}]},{"cell_type":"code","source":"# let's check our transcription - looks spot on!\nprint(text)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-02-28T22:15:35.392713Z","iopub.execute_input":"2024-02-28T22:15:35.393064Z","iopub.status.idle":"2024-02-28T22:15:35.397826Z","shell.execute_reply.started":"2024-02-28T22:15:35.393040Z","shell.execute_reply":"2024-02-28T22:15:35.396908Z"},"trusted":true},"execution_count":83,"outputs":[{"name":"stdout","text":"{'text': '‡§π‡•á‡§≤‡•ã ‡§®‡§Æ‡§∏‡•ç‡§ï‡§æ‡§∞ ‡§∏‡§∞ ‡§Æ‡•à‡§Ç ‡§°‡§ø‡§™‡§æ‡§∞‡•ç‡§ü‡§Æ‡•á‡§Ç‡§ü ‡§ë‡§´‡§º ‡§∏‡•á‡§°‡§Æ‡§ø‡§®‡§ø‡§∏‡•ç‡§ü‡•á‡§ü‡•Ä ‡§°‡§ø‡§™‡§æ‡§∞‡•ç‡§ü‡§Æ‡•á‡§Ç‡§ü ‡§∏‡§Ç‡§™‡§§‡•ç‡§§‡§ø ‡§ú‡§ø‡§∏‡§ï‡•Ä ‡§§‡§∞‡§´ ‡§ê‡§∏‡•Ä ‡§∏‡§≠‡•ç‡§Ø ‡§ï‡§æ ‡§¨‡§æ‡§§ ‡§ï‡§∞‡•Ç‡§Å ‡§ï‡•ç‡§Ø‡§æ ‡§Æ‡•á‡§∞‡•Ä ‡§¨‡§∏ ‡§ê‡§∏‡•Ä ‡§Ü‡§Æ ‡§ú‡•Ä ‡§ï‡•ã ‡§∞‡§ø‡§™‡•ã‡§∞‡•ç‡§ü‡§∞ ‡§®‡§π‡•Ä‡§Ç ‡§µ‡•ã ‡§â‡§∏‡§ï‡•ã ‡§™‡•á‡§∞‡§ø‡§∏ ‡§¨‡•ã‡§≤ ‡§∞‡§π‡•ã ‡§π‡•à ‡§ú‡•Ä ‡§∏‡§∞ ‡§Æ‡•à‡§Ç ‡§â‡§®‡•ç‡§π‡•ã‡§Ç‡§®‡•á ‡§®‡§ø‡§∂‡•ç‡§ö‡§ø‡§§ ‡§∞‡§ø‡§™‡•ã‡§∞‡•ç‡§ü‡§∞ ‡§≤‡•á‡§ü‡•Ä‡§ú ‡§Ö‡§™‡§®‡•Ä ‡§∂‡§ø‡§ï‡§æ‡§Ø‡§§ ‡§¶‡§∞‡•ç‡§ú ‡§ï‡§ø‡§Ø‡§æ ‡§•‡§æ ‡§∏‡§§‡•ç‡§§‡§æ‡§à‡§∏ ‡§Ö‡§ó‡§∏‡•ç‡§§ ‡§ï‡•ã ‡§¶‡•ã ‡§π‡§ú‡§æ‡§∞ ‡§§‡•á‡§à‡§∏ ‡§Æ‡•á‡§Ç ‡§ï‡•ç‡§Ø‡§æ ‡§Ü‡§™‡§ï‡•ã ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§π‡•ã‡§ó‡•Ä ‡§á‡§∏‡§ï‡•á ‡§¨‡§æ‡§∞‡•á ‡§Æ‡•á‡§Ç ‡§π‡§æ‡§Å ‡§•‡•ã‡§°‡§º‡§æ ‡§π‡•à ‡§¨‡•ã‡§≤‡•á ‡§ú‡•Ä ‡§∏‡§∞ ‡§á‡§∏‡•Ä ‡§ï‡§æ ‡§∂‡§ø‡§ï‡§æ‡§Ø‡§§ ‡§∏‡§Ç‡§ñ‡•ç‡§Ø‡§æ ‡§á‡§∏‡§ï‡•Ä ‡§∂‡§ø‡§ï‡§æ‡§Ø‡§§ ‡§∏‡§Ç‡§ñ‡•ç‡§Ø‡§æ ‡§π‡•à ‡§ú‡•Ä‡§∞‡•ã ‡§µ‡§® ‡§∏‡•á‡§Æ‡§® ‡§°‡§¨‡§≤ ‡§´‡§æ‡§á‡§µ ‡§•‡•ç‡§∞‡•Ä ‡§§‡§∞‡§π ‡§Ü‡§™‡§ï‡•ã ‡§ú‡§æ‡§®‡§®‡§æ ‡§ö ‡§Æ‡§ø‡§≤‡•á ‡§á‡§∏‡§ï‡•á ‡§¨‡§æ‡§∞‡•á ‡§Æ‡•á‡§Ç ‡§π‡•à ‡§•‡•ã‡§°‡§º‡§æ ‡§π‡•à ‡§¨‡•ã‡§≤‡•á ‡§ú‡•Ä ‡§∏‡§ø‡§∞ ‡§á‡§∏‡•Ä ‡§ï‡§æ ‡§∂‡§ø‡§ï‡§æ‡§Ø‡§§ ‡§∏‡§Ç‡§ñ‡•ç‡§Ø‡§æ ‡§π‡•à ‡§ú‡•Ä‡§∞‡•ã ‡§µ‡§® ‡§∏‡•á‡§Æ‡§® ‡§°‡§¨‡§≤ ‡§∏‡•á‡§Æ ‡§´‡§æ‡§á‡§µ ‡§•‡•ç‡§∞‡•Ä ‡§∏‡§ø‡§∞ ‡§Ü‡§™‡§ï‡•ã ‡§ú‡§æ‡§®‡§®‡§æ ‡§ö‡§æ‡§π‡•á‡§Ç‡§ó‡•á ‡§ï‡•Ä ‡§Ü‡§™‡§ï‡•ã ‡§∏‡§¶‡§∏‡•ç‡§Ø ‡§ï‡§æ ‡§∞‡§ø‡§™‡•ç‡§≤‡§æ‡§à ‡§ú‡•Ä ‡§ú‡§µ‡§æ‡§¨ ‡§°‡§ø‡§™‡§æ‡§∞‡•ç‡§ü‡§Æ‡•á‡§Ç‡§ü ‡§ï‡•á ‡§¶‡•ç‡§µ‡§æ‡§∞‡§æ ‡§ó‡•ç‡§Ø‡§æ‡§∞‡§π ‡§∏‡§ø‡§§‡§Æ‡•ç‡§¨‡§∞ ‡§ï‡•ã ‡§¶‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ ‡§π‡•à ‡§ï‡•Ä ‡§Ü‡§™‡§®‡•á ‡§â‡§∏‡•á ‡§ö‡•á‡§ï ‡§ï‡§∞ ‡§≤‡§ø‡§Ø‡§æ ‡§î‡§∞ ‡§Ü‡§™ ‡§Ö‡§®‡§ï‡•ã‡§∑ ‡§†‡§æ‡§∞‡•Ç ‡§∞‡•Ç‡§™‡§Ø‡§æ ‡§á‡§∏‡§∏‡•á ‡§î‡§∞ ‡§ï‡•ã‡§à ‡§Ö‡§µ‡§æ‡§∞‡•ç‡§° ‡§ï‡•á ‡§≤‡§ø‡§è ‡§® ‡§Æ‡•à‡§°‡§Æ ‡§á‡§∏‡§≤‡§ø‡§è ‡§Ø‡•á ‡§ï‡§ø‡§Ø‡§æ ‡§•‡§æ ‡§ú‡•Ä ‡§ú‡•Ä ‡§ú‡•Ä ‡§∏‡§¨‡§ï‡•ã ‡§π‡§Æ ‡§¨‡§§‡§æ ‡§¶‡•á‡§§‡•á ‡§π‡•à ‡§ï‡•Ä ‡§â‡§®‡•ç‡§π‡•ã‡§Ç‡§®‡•á ‡§ï‡§ø‡§∏ ‡§™‡•ç‡§∞‡§ï‡§æ‡§∞ ‡§Æ‡•á‡§Ç ‡§Ø‡•á ‡§∂‡§ø‡§ï‡§æ‡§Ø‡§§ ‡§¶‡§∞‡•ç‡§ú ‡§ï‡•Ä ‡§§‡•ã ‡§Ø‡§æ ‡§¶‡§∞‡•ç‡§ú ‡§¶‡§∞‡•ç‡§ú ‡§ú‡•Ä ‡§ú‡•Ä ‡§Ø‡§π ‡§µ‡§æ‡§∞‡•ç‡§° ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ï‡§ø‡§Ø‡§æ ‡§•‡§æ ‡§® ‡§ú‡•Ä ‡§ú‡•Ä ‡§¨‡§ø‡§≤‡•ç‡§ï‡•Å‡§≤ ‡§∏‡§∞ ‡§î‡§∞ ‡§µ‡§æ‡§∞‡•ç‡§° ‡§∏‡•á ‡§∞‡§ø‡§≤‡•á‡§ü‡•á‡§° ‡§Æ‡•á‡§Ç ‡§ï‡•Ä ‡§∂‡§ø‡§ï‡§æ‡§Ø‡§§ ‡§•‡•Ä ‡§π‡§æ‡§Å ‡§π‡§æ‡§Å ‡§ú‡•Ä ‡§ú‡•Ä ‡§∏‡§∞ ‡§§‡•ã ‡§Ü‡§™‡§ï‡•ã ‡§ú‡§ø‡§∏‡§ï‡§æ ‡§∞‡§ø‡§∏‡•ç‡§™‡•ç‡§≤‡§æ‡§à ‡§ó‡•Å‡§ú‡§µ‡§æ‡§¨ ‡§Ü‡§∞‡•ã‡§™ ‡§°‡§ø‡§™‡§æ‡§∞‡•ç‡§ü‡§Æ‡•á‡§Ç‡§ü ‡§ï‡•á ‡§¶‡•ç‡§µ‡§æ‡§∞‡§æ ‡§ó‡•ç‡§Ø‡§æ‡§∞‡§π ‡§∏‡§ø‡§§‡§Æ‡•ç‡§¨‡§∞ ‡§ï‡•ã ‡§¶‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ ‡§π‡•à ‡§ï‡•Ä ‡§Ü‡§™‡§®‡•á ‡§â‡§∏‡•á ‡§∏‡•ç‡§µ‡•á‡§ï ‡§ï‡§∞ ‡§≤‡§ø‡§Ø‡§æ ‡§π‡•à ‡§Ü‡§™ ‡§ö‡•á‡§ï ‡§®‡§π‡•Ä‡§Ç ‡§ï‡§ø‡§Ø‡§æ ‡§®‡§π‡•Ä‡§Ç ‡§ú‡•Ä ‡§∏‡§ø‡§∞ ‡§Ø‡§¶‡§ø ‡§Ü‡§™‡§®‡•á ‡§â‡§∏‡•á ‡§ö‡•á‡§ï ‡§®‡§π‡•Ä‡§Ç ‡§ï‡§ø‡§Ø‡§æ ‡§§‡•ã ‡§π‡§Æ ‡§Ü‡§™‡§ï‡•ã ‡§¨‡§§‡§æ ‡§¶‡•á‡§§‡•á ‡§π‡•à ‡§ï‡•Ä ‡§á‡§∏‡§Æ‡•á‡§Ç ‡§Ü‡§™‡§ï‡•ã ‡§ï‡•ç‡§Ø‡§æ ‡§ú‡§µ‡§æ‡§¨ ‡§¶‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ ‡§π‡•à ‡§á‡§∏‡§Æ‡•á‡§Ç ‡§∏‡§Æ‡•Ä‡§ï‡•ç‡§∑‡§æ ‡§ú‡§æ‡§§‡§æ ‡§π‡•à ‡§ï‡•Ä ‡§Ü‡§™ ‡§ê‡§∏‡•Ä ‡§Ö‡§®‡•Å‡§∞‡•ã‡§ß ‡§π‡•à ‡§ï‡•Ä ‡§ï‡•É‡§™‡•ç‡§Ø‡§æ ‡§®‡§ø‡§∞‡•ç‡§Æ‡§ø‡§§ ‡§™‡•ã‡§∞‡•ç‡§ü‡§≤ ‡§Ü‡§∞‡•ã‡§™ ‡§™‡•Å‡§∞‡§∏‡•ç‡§ï‡§æ‡§∞ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Ü‡§µ‡•á‡§¶‡§® ‡§ï‡§∞‡•á ‡§∏‡§ø‡§∞ ‡§Ø‡§π ‡§ú‡§µ‡§æ‡§¨ ‡§â‡§∏‡§ï‡§æ ‡§°‡§ø‡§™‡§æ‡§∞‡•ç‡§ü‡§Æ‡•á‡§Ç‡§ü ‡§ï‡•á ‡§¶‡•ç‡§µ‡§æ‡§∞‡§æ ÔøΩ‡§∏‡§ï‡§æ ‡§°‡§ø‡§™‡§æ‡§∞‡•ç‡§ü‡§Æ‡•á‡§Ç‡§ü ‡§ï‡•á ‡§¶‡•ç‡§µ‡§æ‡§∞‡§æ ‡§¶‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ ‡§π‡•à ‡§∏‡§ø‡§∞ ‡§§‡•ã ‡§ï‡•ç‡§Ø‡§æ ‡§Ü‡§™ ‡§π‡•Ä ‡§ú‡§µ‡§æ‡§¨ ‡§ê‡§∏‡•Ä ‡§∏‡§Ç‡§§‡•Å‡§∑‡•ç‡§ü ‡§π‡•à ‡§î‡§∞ ‡§∏‡§Ç‡§§‡•Å‡§∑‡•ç‡§ü ‡§π‡•à ‡§Ü‡§™ ‡§ï‡•ç‡§Ø‡§æ ‡§¨‡•ã‡§≤‡•á ‡§î‡§∞ ‡§è‡§ï ‡§¨‡§æ‡§∞ ‡§∞‡§ø‡§™‡•ã‡§∞‡•ç‡§ü ‡§ï‡•Ä‡§ú‡§ø‡§Ø‡•á ‡§µ‡§ó‡•à‡§∞‡§π ‡§ï‡•Ä ‡§Ü‡§™‡§ï‡•á ‡§Ö‡§®‡•Å‡§∞‡•ã‡§ß ‡§π‡•à ‡§ï‡•Ä ‡§ï‡•É‡§™‡•ç‡§Ø‡§æ ‡§®‡§ø‡§∞‡•ç‡§Æ‡§ø‡§§ ‡§™‡•ã‡§∞‡•ç‡§ü‡§≤ ‡§Ü‡§∞‡•ã‡§™ ‡§™‡•Å‡§∞‡§∏‡•ç‡§ï‡§æ‡§∞ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Ü‡§µ‡•á‡§¶‡§® ‡§ï‡§∞‡•á ‡§∏‡§ø‡§∞ ‡§Ü‡§™ ‡§ì‡§π ‡§ú‡•Ä ‡§∏‡§ø‡§∞ ‡§Ø‡•á ‡§ú‡§µ‡§æ‡§¨ ‡§Ü‡§™‡§ï‡•ã ‡§¶‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ ‡§π‡•à ‡§°‡§ø‡§™‡§æ‡§∞‡•ç‡§ü‡§Æ‡•á‡§Ç‡§ü ‡§ï‡•á ‡§¶‡•ç‡§µ‡§æ‡§∞‡§æ ‡§§‡•ã ‡§Ü‡§™ ‡§π‡•Ä ‡§ú‡§µ‡§æ‡§¨ ‡§ê‡§∏‡•Ä ‡§∏‡§Ç‡§§‡•Å‡§∑‡•ç‡§ü ‡§π‡•à ‡§π‡•à ‡§∏‡§¨ ‡§∏‡•Å‡§®‡•ç‡§¶‡§∞ ‡§ú‡•Ä‡§§ ‡§π‡•à ‡§Ü‡§™ ‡§∞‡•á‡§ü‡§ø‡§Ç‡§ó ‡§ï‡§æ ‡§¶‡•á‡§®‡§æ ‡§ö‡§æ‡§π‡•á‡§Ç‡§ó‡•á ‡§∏‡§Ç‡§§‡•Å‡§∑‡•ç‡§ü ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ó‡•Å‡§° ‡§™‡•à‡§∞‡•Ä ‡§ó‡•Å‡§° ‡§Ø‡§æ ‡§è‡§ï‡•ç‡§∏‡•á‡§≤‡§Æ ‡§π‡•à ‡§†‡•Ä‡§ï ‡§π‡•à ‡§è‡§ï‡•ç‡§∏‡•á‡§≤‡§Æ ‡§ï‡•á ‡§π‡•ã‡§ó‡§æ ‡§•‡•à‡§Ç‡§ï‡•ç‡§Ø‡•Ç ‡§∏‡•á ‡§π‡•ã ‡§Æ‡§π‡•ã‡§§‡•ç‡§∏‡§µ ‡§á‡§∏‡§ï‡•á ‡§Ö‡§§‡§ø‡§∞‡§ø‡§ï‡•ç‡§§ ‡§Ü‡§™‡§§ ‡§Æ‡•á‡§Ç ‡§î‡§∞ ‡§ï‡•Å‡§õ ‡§∏‡•Å‡§ù‡§æ‡§µ ‡§ï‡•ã ‡§µ‡§ø‡§ö‡§æ‡§∞‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§¨‡§§‡§æ‡§®‡§æ ‡§ö‡§æ‡§π‡•á‡§Ç‡§ó‡•á ‡§ú‡§ø‡§∏‡§∏‡•á ‡§∏‡§∞‡•ç‡§µ‡§ø‡§∏ ‡§Æ‡•á‡§Ç ‡§∏‡•Å‡§ß‡§æ‡§∞ ‡§ï‡§ø‡§è ‡§ú‡§æ ‡§∏‡§ï‡•á ‡§Ü‡§ú ‡§Ü‡§á‡§Ø‡•á ‡§ú‡•Ä ‡§´‡•à‡§ï‡•ç‡§ö‡•Å‡§≤‡•Ä ‡§Æ‡•à‡§Ç ‡§ú‡•Ä ‡§π‡•Ç‡§Å ‡§´‡•à‡§ï‡•ç‡§ö‡•Å‡§≤‡•Ä ‡§Ü‡§™ ‡§¨‡•á‡§π‡§§‡§∞ ‡§ï‡•á ‡§¨‡•á‡§π‡§§‡§∞ ‡§á‡§§‡§®‡§æ ‡§â‡§†‡§æ‡§è ‡§ï‡•ç‡§Ø‡§æ ‡§®‡§π‡•Ä‡§Ç ‡§ú‡•Ä ‡§π‡•Ç‡§Å ‡§•‡§Ç‡§¨ ‡§ï‡•Ä ‡§∏‡•ã‡§® ‡§Ü‡§à ‡§∏‡•ã‡§∞ ‡§Ü‡§™‡§ï‡§æ ‡§∏‡§∞ ‡§Ø‡•á ‡§´‡•Ä‡§°‡§¨‡§ï ‡§π‡§Æ ‡§Æ‡•á‡§Ç‡§∂‡§® ‡§ï‡§∞‡§ï‡•á ‡§Ü‡§ó‡•á ‡§ï‡§Ç‡§ö‡§®‡§∞ ‡§•‡§∞‡•ç‡§ü‡•Ä ‡§ï‡•ã ‡§∂‡•á‡§Ø‡§∞ ‡§ï‡§∞ ‡§¶‡•á ‡§§‡•ã ‡§§‡§æ‡§ï‡§ø ‡§Ü‡§™‡§ï‡•ã ‡§ê‡§∏‡•Ä ‡§∏‡•Å‡§µ‡§ø‡§ß‡§æ ‡§Æ‡§ø‡§≤‡§§‡•Ä ‡§∞‡§π‡•á ‡§î‡§∞ ‡§≠‡§µ‡§ø‡§∑‡•ç‡§Ø ‡§Æ‡•á‡§Ç ‡§Ü‡§™‡§ï‡•ã ‡§ï‡•ã‡§à ‡§≠‡•Ä ‡§∞‡§ø‡§µ‡§æ‡§Ç‡§ö ‡§ï‡§∞‡§§‡•á ‡§§‡•ã ‡§Ü‡§™‡§ï‡•ã ‡§ê‡§∏‡•á ‡§π‡•Ä ‡§ú‡§≤‡•ç‡§¶ ‡§ê‡§∏‡•Ä ‡§ú‡§≤‡•ç‡§¶ ‡§∏‡§Æ‡§æ‡§ß‡§æ‡§® ‡§¶‡§ø‡§Ø‡§æ ‡§ú‡§æ‡§è ‡§∏‡§ø‡§∞ ‡§ú‡•Ä ‡§∏‡§ø‡§∞ ‡§ï‡•Ä‡§Æ‡§§‡•Ä ‡§∏‡§Æ‡§Ø ‡§¶‡•á‡§®‡•á ‡§ï‡•ã ‡§µ‡•á‡§≤‡§ï‡§Æ ‡§∏‡§ø‡§∞ ‡§ï‡•Ä‡§Æ‡§§‡•Ä ‡§∏‡§Æ‡§Ø ‡§¶‡•á‡§®‡•á ‡§ï‡•ã ‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶ ‡§Ü‡§™‡§ï‡§æ ‡§¶‡§ø‡§® ‡§∂‡•Å‡§≠ ‡§π‡•ã ‡§∏‡§ø‡§∞ ‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶'}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Run it again!","metadata":{}},{"cell_type":"markdown","source":"Now let's step it up a notch. Let's try transcribing 30 minutes of audio from the LibriSpeech dataset. We'll first load up the second sample from our dataset, which corresponds to the 30 min audio file. We'll then pass the audio to the model for transcription, again timing how long the foward pass takes:","metadata":{}},{"cell_type":"code","source":"audio = test_dataset[1][\"audio\"]  # load the second sample (30 mins) and get the audio array\n\naudio_length_in_mins = len(audio[\"array\"]) / audio[\"sampling_rate\"] / 60\nprint(f\"Audio is {audio_length_in_mins} mins.\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# transcribe using cached function\n%time text = pipeline(audio)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Just 35s to transcribe for 30 mins of audio! That means you could transcribe an entire 2 hour movie in under 2.5 minutes ü§Ø By increasing the batch size, we could also reduce the transcription time for long audio files further: increasing the batch size by 2x roughly decreases the transcription time by 2x, provided the overall batch size is less than the total audio time.\n\nIf you're fortunate enough to have access to a TPU v4, you'll find that the transcription times a factor of 2 faster than on a v3 - you can quickly see how we can get super fast transcription times using Whisper JAX on TPU!","metadata":{}},{"cell_type":"markdown","source":"## ‚è∞ Timestamps and more\n\nWe can also get timestamps from the model by passing `return_timestamps=True`, but this will require a recompilation since we change the signature of the forward pass. \n\nThe timestamps compilation takes longer than the non-timestamps one. Luckily, because we initialised our compilation cache above, we're not starting from scratch in compiling this time. This is the last compilation we need to do!","metadata":{}},{"cell_type":"code","source":"# compile the forward call with timestamps - slow but we only do once\n%time outputs = pipeline(audio, return_timestamps=True)\ntext = outputs[\"text\"]  # transcription\nchunks = outputs[\"chunks\"]  # transcription + timestamps","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# use cached timestamps function - super fast!\n%time outputs = pipeline(audio, return_timestamps=True)\ntext = outputs[\"text\"] \nchunks = outputs[\"chunks\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We've shown how you can transcibe an audio file in English. The pipeline is also compatible with two further arguments that you can use to control the generation process. It's perfectly fine to omit these if you want speech transcription and the Whisper model to automatically detect which language the audio is in. Otherwise, you can change them depending on your task/language:\n\n\n* `task`: task to use for generation, either `\"transcribe\"` or `\"translate\"`. Defaults to `\"transcribe\"`.\n* `language`: language token to use for generation, can be either in the form of `\"<|en|>\"`, `\"en\"` or `\"english\"`. Defaults to `None`, meaning the language is automatically inferred from the audio input. Optional, and only relevant if the source audio language is known a-priori.","metadata":{}},{"cell_type":"markdown","source":"## Used for transcribing cpgrams audio dataser\\t","metadata":{}},{"cell_type":"code","source":"import os\nimport librosa\nimport tqdm\nimport json\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# preprocessing\n# Function to preprocess audio file to 16kHz waveform\ndef preprocess_audio(audio_file):\n    signal, _ = librosa.load(audio_file, sr=16000)\n    return signal","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"files=os.listdir('/kaggle/input/cpgram-audios')\n%cd /kaggle/input/cpgram-audios","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%time\ntranscript={}\nfor f,j in tqdm(wave_dict:\n    transcript[f] = pipeline(j)\n               ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"                \nprint(len(transcript))\nwith open('/kaggle/working/transcript.json', \"w\") as json_file:\n    json.dump(transcript, json_file)","metadata":{},"execution_count":null,"outputs":[]}]}